# -*- coding: utf-8 -*-
"""new_m.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bHj5wS5GYqnhMV4gO7-hCzmUf-YUegx6
"""

import numpy as np
import pandas as pd
import random

import torch
import torch.optim as optim
import scipy.io
import torch.nn as nn
import torch.nn.functional as F
from torch.nn.parameter import Parameter
from sklearn.model_selection import train_test_split



import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from sklearn.metrics import accuracy_score, balanced_accuracy_score
from google.colab import drive
drive.mount('/content/drive')

df=pd.read_csv('Normal Data')
df=df.drop(df.columns[0], axis=1)
labels=list(df.iloc[:,-1])
labels=pd.DataFrame({'labels':labels})

df=df.drop(df.columns[3],axis=1)

X_train, X_test, y_train, y_test = train_test_split(df, labels, test_size=0.2, random_state=42, shuffle=True)

X_train, X_test, y_train, y_test = map(torch.tensor,(X_train.values, X_test.values, y_train.values, y_test.values))

'''
path='/content/drive/MyDrive/hyperplane.mat'
data=scipy.io.loadmat(path)
data=data.get('data')
data=pd.DataFrame(data)

labels=data.iloc[:,4]

label=pd.DataFrame(labels)
data=data.drop(columns=5,axis=1)
data=data.drop(columns=4,axis=1)




X_train, X_test, y_train, y_test = train_test_split(df, labels, test_size=0.2, random_state=42, shuffle=True)

X_train, X_test, y_train, y_test = map(torch.tensor,(X_train.values, X_test.values, y_train.values, y_test.values))

'''

'''
test_y=pd.read_csv('/content/drive/MyDrive/SEA_data (1)/SEA_testing_class (1).csv')

test_x=pd.read_csv('/content/drive/MyDrive/SEA_data (1)/SEA_testing_data (1).csv')
train_y=pd.read_csv('/content/drive/MyDrive/SEA_data (1)/SEA_training_class (1).csv')
train_x=pd.read_csv('/content/drive/MyDrive/SEA_data (1)/SEA_training_data (1).csv')
train_x=np.asarray(train_x)

train_y=np.asarray(train_y)
test_x=np.asarray(test_x)
test_y=np.asarray(test_y)
'''

'''
fig=plt.figure(figsize=(10,8))
ax=Axes3D(fig)
ax.scatter(train_x[:250,0],train_x[:250,1],train_x[:250,2],c=train_y[:250])
'''

#test_y,test_x,train_y,train_x=map(torch.tensor,(test_y,test_x,train_y,train_x))

class net(nn.Module):
  def __init__(self):
    super(net,self).__init__()

    self.Linear1=nn.Linear(3,20,bias=None)
    self.Linear2=nn.Linear(20,20,bias=None)
    self.Linear3=nn.Linear(20,20,bias=None)
    self.Linear4=nn.Linear(20,4,bias=None)

    self.Sigmoid=nn.Sigmoid()

  def forward(self,input):
    out1=self.Linear1(input)
    out1s=self.Sigmoid(out1)
    out2=self.Linear2(out1s)
    out2s=self.Sigmoid(out2)
    out3=self.Linear3(out2s)
    out3s=self.Sigmoid(out3)
    out4=self.Linear4(out3s)
    out=self.Sigmoid(out4)

    return out



#CODE FOR ARTIFICIAL DATSET

'''
model=net()
model.double()
optimizer = optim.SGD(model.parameters(), lr=0.4)
j=0
Acc=[]

L=[]
for i in range(len(train_x)):


  #print('\nfor instance {}...\n'.format(i+1))  
  #train_x[i]= train_x[i].unsqueeze(0)
  pred=model(train_x[i])

  pred=pred.reshape((1,3))
  criterion=nn.CrossEntropyLoss()
  loss=criterion(pred,train_y[i])
  model.zero_grad()
  
  loss.backward()
  optimizer.step()
  L.append(loss)

  if (i%250==0 and i!=0):
   
    print("training loss",torch.Tensor(L).mean())
    print("Training examples {} are processed".format(i))

    predictions=model(test_x[j:i]) 

    
    Pred=torch.argmax(predictions,1)

    Acc.append(accuracy_score(test_y[j:i], Pred))

    print("Online Accuracy: {}".format(accuracy_score(test_y[j:i], Pred)))
    
    j=j+250
    
    #print("{} Examples  are Tested\n".format(j))
   


    alpha_w = 0.05;
    alpha_d = 0.04;
    alpha   = 0.01;
    dt1=Pred
    acc=[]
    for i in range(len(dt1)):
      if dt1[i]==test_y[i]:
        acc.append(0)
      else:
        acc.append(1)

    cuttingpoint = 0
    pp = len(dt1)
    F_cut = acc
    Fupper = np.max(F_cut)
    Flower = np.min(F_cut)
    miu_F = np.mean(F_cut)

    for idx in range(pp):
      cut = idx + 1
      miu_G = np.mean(F_cut[0:cut])
      Gupper = np.max(F_cut[0:cut])
      Glower = np.min(F_cut[0:cut])
      epsilon_G = (Gupper - Glower) * np.sqrt(((pp)/(2*cut*(pp)) * np.log(1/alpha)))
      epsilon_F = (Fupper - Flower) * np.sqrt(((pp)/(2*cut*(pp)) * np.log(1/alpha)))

      if ((epsilon_G + miu_G) >= (miu_F + epsilon_F) and cut<pp):
          cuttingpoint = cut
          print("cut",cuttingpoint)
          miu_H = np.mean(F_cut[(cuttingpoint):])
          epsilon_D = (Fupper - Flower) * np.sqrt(((pp-cuttingpoint)/(2*cuttingpoint*(pp-cuttingpoint)) * np.log(1/alpha_d)))
          epsilon_W = (Fupper - Flower) * np.sqrt(((pp-cuttingpoint)/(2*cuttingpoint*(pp-cuttingpoint)) * np.log(1/alpha_w)))
          print((miu_G,miu_H),epsilon_D)
          print("\n")
          break

    if((np.abs(miu_G - miu_H)) > epsilon_D and cuttingpoint>1):
      print('Drift state: DRIFT\n')

    elif((np.abs(miu_G - miu_H)) >= epsilon_W and (np.abs(miu_G - miu_H)) < epsilon_D):
      print('Drift state: WARNING\n')

    else:
      print('Drift state: STABLE\n')
'''

path='Anomaly data'
df=pd.read_csv(path)
df=df.drop(columns='Unnamed: 0')
y=pd.DataFrame(df.iloc[:,-1])
df=df.drop(df.columns[3],axis=1)
x_t=torch.tensor(df.values)
y_t=torch.tensor(y.values)

# CODE FOR SENSOR DATASET 


model=net()
model.double()
optimizer = optim.SGD(model.parameters(), lr=0.4)
j=0
Acc=[]
d=[]
w=[]
L=[]
for i in range(100000):


  #print('\nfor instance {}...\n'.format(i+1))  
  #train_x[i]= train_x[i].unsqueeze(0)
  pred=model(X_train[i])

  pred=pred.reshape((1,4))
  criterion=nn.CrossEntropyLoss()
  loss=criterion(pred,y_train[i])
  model.zero_grad()
  
  loss.backward()
  optimizer.step()
  L.append(loss)

  if (i%1000==0):
   
    print("training loss",torch.Tensor(L).mean())
    print("Training examples {} are processed".format(i))

    predictions=model(x_t) 

    
    Pred=torch.argmax(predictions,1)

    Acc.append(accuracy_score(y_t, Pred))

    print("Online Accuracy: {}".format(accuracy_score(y_t, Pred)))
    #j=j+250
    
    #print("{} Examples  are Tested\n".format(j))
   
    

    alpha_w = 0.05;
    alpha_d = 0.04;
    alpha   = 0.01;
    dt1=Pred
    acc=[]
    for i in range(len(dt1)):
      if dt1[i]==y_t[i]:
        acc.append(0)
      else:
        acc.append(1)

    cuttingpoint = 0
    pp = len(dt1)
    F_cut = acc
    Fupper = np.max(F_cut)
    Flower = np.min(F_cut)
    miu_F = np.mean(F_cut)

    for idx in range(pp):
      cut = idx + 1
      miu_G = np.mean(F_cut[0:cut])
      Gupper = np.max(F_cut[0:cut])
      Glower = np.min(F_cut[0:cut])
      epsilon_G = (Gupper - Glower) * np.sqrt(((pp)/(2*cut*(pp)) * np.log(1/alpha)))
      epsilon_F = (Fupper - Flower) * np.sqrt(((pp)/(2*cut*(pp)) * np.log(1/alpha)))

      if ((epsilon_G + miu_G) >= (miu_F + epsilon_F) and cut<pp):
          cuttingpoint = cut
          miu_H = np.mean(F_cut[(cuttingpoint):])
          epsilon_D = (Fupper - Flower) * np.sqrt(((pp-cuttingpoint)/(2*cuttingpoint*(pp-cuttingpoint)) * np.log(1/alpha_d)))
          epsilon_W = (Fupper - Flower) * np.sqrt(((pp-cuttingpoint)/(2*cuttingpoint*(pp-cuttingpoint)) * np.log(1/alpha_w)))
         # print((miu_G,miu_H),epsilon_D)
          print("\n")
          break

    if((np.abs(miu_G - miu_H)) > epsilon_D and cuttingpoint>1):
      print("cut",cuttingpoint)
      print((miu_G,miu_H),epsilon_D)

      print('Drift state: DRIFT\n')

    elif((np.abs(miu_G - miu_H)) >= epsilon_W and (np.abs(miu_G - miu_H)) < epsilon_D):
      print("cut",cuttingpoint)

      print('Drift state: WARNING\n')

    else:
      print('Drift state: STABLE\n')



import matplotlib.pyplot as plt
figure=plt.figure(figsize=(10,10))
epochs=range(0,100)
plt.plot(epochs,Acc,'g')
plt.xlabel("Sequencewise_Data")
plt.ylabel(" Testdata_Accuracy")
plt.title("Sensor-Data")





